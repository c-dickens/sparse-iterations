{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketching Unconstrained Least Squares\n",
    "\n",
    "Now that it seems the sketching methods are working, we are in a position to test how the count sketch transform can be used to speed up the solving of a constrained regression problem.  To begin with, we will focus on the unconstrained case and measure how the time varies across using diferent data sizes as well as the density of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from countSketch import countSketch_elt_stream \n",
    "from srht import srht_transform\n",
    "from time import time\n",
    "import itertools\n",
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_hessian_general(data, targets, sketch_size,\n",
    "                      num_iters):\n",
    "    '''\n",
    "    INPUT:\n",
    "    data - n x d matrix\n",
    "    targets - n x 1 target variables\n",
    "    num_iters - how many iterations to perform.  \n",
    "    Need log(1/eps) -- > num_iters for eps accuracy where\n",
    "    eps is relative error in the semi-norm ||u-v||_A = \n",
    "    1/sqrt(n)*||A(u-v)||_2.\n",
    "    \n",
    "    OUTPUT:\n",
    "    x0 - vector which approximately recovers the true solution to \n",
    "    the constrained problem\n",
    "    \n",
    "    \n",
    "    \n",
    "    TO DO:\n",
    "    Add functionality for lower bound on sketch size\n",
    "    '''\n",
    "    \n",
    "    A = data\n",
    "    #tidy_data =  sort_row_order(A)\n",
    "    \n",
    "    y = targets\n",
    "    n,d = A.shape\n",
    "    x0 = np.zeros(shape=(d,1))\n",
    "    m = int(sketch_size) # sketching dimension\n",
    "    \n",
    "    ATy = A.T@y[:,None]\n",
    "    covariance_mat = A.T.dot(A)\n",
    "    #print(\"A^Ty shape: {}\".format(ATy.shape))\n",
    "    #print(\"covariance shape: {}\".format(covariance_mat.shape))\n",
    "   \n",
    "    for n_iter in range(int(num_iters)):\n",
    "        S_A = countSketch_elt_stream(A, sketch_size)\n",
    "        \n",
    "        true_norm = np.linalg.norm(A@x0)**2\n",
    "        approx_norm = np.linalg.norm(S_A@x0)**2\n",
    "        B = S_A.T.dot(S_A)\n",
    "        z = ATy + np.dot(S_A.T, np.dot(S_A,x0))- covariance_mat@x0 #\n",
    "        x_new = np.linalg.lstsq(B,z)[0]\n",
    "        x0 = x_new # # need to convert to vector format as \n",
    "                           # the sparse solver is different output\n",
    "    return np.ravel(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function allows for the generation of sparse data similar to the `sklearn` method but with the added flexibility of being able to set sparsity as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def generate_sparse_data(n_samples, n_features, density,\n",
    "                         n_targets=1, bias = 0.0, tail_strength=0.5,\n",
    "                        noise=0.0, permute=True, coef=True,\n",
    "                        random_state=None):\n",
    "    '''\n",
    "    Generate a random regression problem with a sparse design matrix.\n",
    "    Follow the setup from sklearn.datasets.make_regression except \n",
    "    with sparse matrices and a density parameter.\n",
    "    The output is generate by applying a random linear regression\n",
    "    model with n_features regressors to the generated input and \n",
    "    adding some gaussian noise with adjustable scale.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        The number of samples.\n",
    "    n_features : int\n",
    "        The number of features.\n",
    "    density : float in (0,1)\n",
    "        density of the data to be generated.\n",
    "    n_targets : int, optional (default=1)\n",
    "        The number of regression targets, i.e., the dimension of the y output\n",
    "        vector associated with a sample. By default, the output is a scalar.\n",
    "    bias : float, optional (default=0.0)\n",
    "        The bias term in the underlying linear model.\n",
    "    tail_strength : float between 0.0 and 1.0, optional (default=0.5)\n",
    "        The relative importance of the fat noisy tail of the singular values\n",
    "        profile if `effective_rank` is not None.\n",
    "    noise : float, optional (default=0.0)\n",
    "        The standard deviation of the gaussian noise applied to the output.\n",
    "    shuffle : boolean, optional (default=True)\n",
    "        Shuffle the samples and the features.\n",
    "    coef : boolean, optional (default=True)\n",
    "        If True, the coefficients of the underlying linear model are returned.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "    Returns\n",
    "    -------\n",
    "    X : SciPy sparse matrix of shape [n_samples, n_features].\n",
    "        Note that it may often be required to use as a NumPy \n",
    "        ndarray so use .toarray() on the output.\n",
    "        e.g removing any zero rows. Defines the input samples.\n",
    "    y : array of shape [n_samples] or [n_samples, n_targets]\n",
    "        The output values.\n",
    "    coef : array of shape [n_features] or [n_features, n_targets], optional\n",
    "        The coefficient of the underlying linear model. It is returned only if\n",
    "        coef is True.'''\n",
    "    random_state = np.random.seed(random_state)\n",
    "    X = sparse.random(m=n_samples, n=n_features,density=density,\n",
    "                     random_state=random_state)\n",
    "    \n",
    "    # In future can add n_informative to extend data generation\n",
    "    ground_truth = np.zeros((n_features, n_targets))\n",
    "    ground_truth = np.random.rand(n_features,n_targets)\n",
    "    \n",
    "    y = X@ground_truth + bias\n",
    "    \n",
    "    # Add noise\n",
    "    if noise > 0.0:\n",
    "        y += random.normal(scale=noise, size=y.shape)\n",
    "        \n",
    "    # Randomly permute samples and features\n",
    "    if permute:\n",
    "        X,y = shuffle(X,y, random_state=random_state)\n",
    "        indices = np.arange(n_features)\n",
    "        np.random.shuffle(indices)\n",
    "        X[:,:] = X[:,indices]\n",
    "        ground_truth = ground_truth[indices]\n",
    "    y = np.squeeze(y)\n",
    "    X = X.toarray()\n",
    "    if coef:\n",
    "        return X,y, np.squeeze(ground_truth)\n",
    "    else:\n",
    "        return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up a parameter grid which will define instances of varying parameters over size, dimension, density, and sketch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': [10, 100, 250],\n",
       " 'density': [0.01],\n",
       " 'rows': [10000, 25000, 50000],\n",
       " 'sketch type': ['CWT', 'None']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'rows' : [10000, 25000, 50000],\n",
    "    'columns' : [10, 100, 250],\n",
    "    'density' : [0.01],#, 0.1, 0.25],#, 0.5, 1.0],\n",
    "    'sketch type' : ['CWT', 'None', ],# 'SRHT']\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup independent variables\n",
    "\n",
    "\n",
    "# Experimental output\n",
    "experiment_output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n,d): (10000,10), density: 0.01, Method CWT\n",
      "Sketch size: 100\n",
      "IHS CWT Solve time: 0.013244152069091797\n",
      "(n,d): (10000,10), density: 0.01, Method None\n",
      "Sketch size: 100\n",
      "System Solve time: 0.0013375282287597656\n",
      "(n,d): (10000,100), density: 0.01, Method CWT\n",
      "Sketch size: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/scipy/sparse/compressed.py:742: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:55: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:17: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IHS CWT Solve time: 0.05049538612365723\n",
      "(n,d): (10000,100), density: 0.01, Method None\n",
      "Sketch size: 1000\n",
      "System Solve time: 0.02021336555480957\n",
      "(n,d): (10000,250), density: 0.01, Method CWT\n",
      "Sketch size: 2500\n",
      "IHS CWT Solve time: 0.22769927978515625\n",
      "(n,d): (10000,250), density: 0.01, Method None\n",
      "Sketch size: 2500\n",
      "System Solve time: 0.09374475479125977\n",
      "(n,d): (25000,10), density: 0.01, Method CWT\n",
      "Sketch size: 100\n",
      "IHS CWT Solve time: 0.018318653106689453\n",
      "(n,d): (25000,10), density: 0.01, Method None\n",
      "Sketch size: 100\n",
      "System Solve time: 0.0025517940521240234\n",
      "(n,d): (25000,100), density: 0.01, Method CWT\n",
      "Sketch size: 1000\n",
      "IHS CWT Solve time: 0.07598543167114258\n",
      "(n,d): (25000,100), density: 0.01, Method None\n",
      "Sketch size: 1000\n",
      "System Solve time: 0.04527854919433594\n",
      "(n,d): (25000,250), density: 0.01, Method CWT\n",
      "Sketch size: 2500\n",
      "IHS CWT Solve time: 0.3624725341796875\n",
      "(n,d): (25000,250), density: 0.01, Method None\n",
      "Sketch size: 2500\n",
      "System Solve time: 0.1752917766571045\n",
      "(n,d): (50000,10), density: 0.01, Method CWT\n",
      "Sketch size: 100\n",
      "IHS CWT Solve time: 0.03152275085449219\n",
      "(n,d): (50000,10), density: 0.01, Method None\n",
      "Sketch size: 100\n",
      "System Solve time: 0.004492282867431641\n",
      "(n,d): (50000,100), density: 0.01, Method CWT\n",
      "Sketch size: 1000\n",
      "IHS CWT Solve time: 0.15548062324523926\n",
      "(n,d): (50000,100), density: 0.01, Method None\n",
      "Sketch size: 1000\n",
      "System Solve time: 0.09551143646240234\n",
      "(n,d): (50000,250), density: 0.01, Method CWT\n",
      "Sketch size: 2500\n",
      "IHS CWT Solve time: 0.5923857688903809\n",
      "(n,d): (50000,250), density: 0.01, Method None\n",
      "Sketch size: 2500\n",
      "System Solve time: 0.4271540641784668\n"
     ]
    }
   ],
   "source": [
    "for n_rows, n_cols, density, method in itertools.product(param_grid['rows'],\n",
    "                                                         param_grid['columns'],\n",
    "                                                         param_grid['density'],\n",
    "                                                         param_grid['sketch type']):\n",
    "    \n",
    "    sketch_size = 10*n_cols\n",
    "    print(\"(n,d): ({},{}), density: {}, Method {}\".format(n_rows, n_cols, density, method))\n",
    "    print(\"Sketch size: {}\".format(sketch_size))\n",
    "    \n",
    "    ### Generate data\n",
    "    data, target, coef = generate_sparse_data(n_rows, n_cols, density)\n",
    "    \n",
    "    if method == 'None':\n",
    "        experiment_output['None'] = {}\n",
    "        # Include a loop here to determine number of samples to take\n",
    "        start = time()\n",
    "        x_true = np.linalg.lstsq(data, target)[0]\n",
    "        solve_time = time() - start\n",
    "        print(\"System Solve time: {}\".format(solve_time))\n",
    "       \n",
    "    if method == \"CWT\":\n",
    "        start = time()\n",
    "        x_sketch = iterative_hessian_general(data, target, sketch_size, num_iters=10)\n",
    "        solve_time = time() - start\n",
    "        print(\"IHS CWT Solve time: {}\".format(solve_time))\n",
    "        \n",
    "    #print(\"Error: {}\".format(np.linalg.norm(data@(x_true - x_cwt))**2))\n",
    "    \n",
    "    del data, target, coef# so don't keep lots of test matrices in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import line_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/scipy/sparse/compressed.py:742: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:55: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "data, target, coef = generate_sparse_data(50000,10,density=0.01)\n",
    "%lprun -f iterative_hessian_general iterative_hessian_general(data,target,100,num_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:55: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.7 ms ± 402 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit iterative_hessian_general(data,target,100,num_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:257: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.81 ms ± 157 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.linalg.lstsq(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit countSketch.countSketch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
